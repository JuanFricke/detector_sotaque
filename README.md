# ğŸ™ï¸ Detector de Sotaque Brasileiro - IA

Sistema completo de detecÃ§Ã£o de sotaques brasileiros usando Deep Learning, com otimizaÃ§Ãµes de multithreading e as melhores prÃ¡ticas de Machine Learning.

## ğŸ“‹ Ãndice

- [CaracterÃ­sticas](#caracterÃ­sticas)
- [Requisitos](#requisitos)
- [InstalaÃ§Ã£o](#instalaÃ§Ã£o)
- [Estrutura do Projeto](#estrutura-do-projeto)
- [Uso](#uso)
- [Modelos DisponÃ­veis](#modelos-disponÃ­veis)
- [OtimizaÃ§Ãµes](#otimizaÃ§Ãµes)
- [Resultados](#resultados)
- [Arquitetura](#arquitetura)

## ğŸ¯ CaracterÃ­sticas

- âœ… **MÃºltiplos Modelos**: CNN, ResNet, Attention CNN, LSTM
- âœ… **Data Augmentation**: Time stretching, pitch shifting, ruÃ­do
- âœ… **Multithreading Otimizado**: DataLoader com workers paralelos
- âœ… **Mixed Precision Training**: Treinamento mais rÃ¡pido com menor uso de memÃ³ria
- âœ… **Early Stopping**: PrevenÃ§Ã£o de overfitting
- âœ… **Learning Rate Scheduling**: Ajuste automÃ¡tico da taxa de aprendizado
- âœ… **VisualizaÃ§Ãµes Completas**: GrÃ¡ficos de treinamento, matriz de confusÃ£o
- âœ… **MÃ©tricas Detalhadas**: AcurÃ¡cia, F1-Score, Precision, Recall
- âœ… **AnÃ¡lise ExploratÃ³ria**: Script completo de EDA

## ğŸ”§ Requisitos

- Python 3.8+
- PyTorch 2.0+
- CUDA (opcional, para GPU)
- 8GB+ RAM recomendado
- GPU com 4GB+ VRAM (opcional)

## ğŸ“¦ InstalaÃ§Ã£o

### 1. Clone o repositÃ³rio
```bash
cd detector_sotaque
```

### 2. Crie um ambiente virtual
```bash
# Windows
python -m venv venv
venv\Scripts\activate

# Linux/Mac
python -m venv venv
source venv/bin/activate
```

### 3. Instale as dependÃªncias
```bash
pip install -r requirements.txt
```

## ğŸ“ Estrutura do Projeto

```
detector_sotaque/
â”œâ”€â”€ sotaque-brasileiro-data/          # Dataset
â”‚   â”œâ”€â”€ accent/                       # Arquivos de Ã¡udio (.wav)
â”‚   â””â”€â”€ sotaque-brasileiro.csv        # Metadados
â”œâ”€â”€ dataset.py                        # Dataset customizado e DataLoaders
â”œâ”€â”€ models.py                         # Arquiteturas de modelos
â”œâ”€â”€ train.py                          # Script de treinamento
â”œâ”€â”€ predict.py                        # Script de inferÃªncia
â”œâ”€â”€ analyze_data.py                   # AnÃ¡lise exploratÃ³ria
â”œâ”€â”€ requirements.txt                  # DependÃªncias
â”œâ”€â”€ README.md                         # DocumentaÃ§Ã£o
â””â”€â”€ experiments/                      # Checkpoints e logs (criado automaticamente)
```

## ğŸš€ Uso

### 1. AnÃ¡lise ExploratÃ³ria dos Dados

Antes de treinar, explore o dataset:

```bash
python analyze_data.py
```

Isso gerarÃ¡:
- VisualizaÃ§Ãµes da distribuiÃ§Ã£o dos dados
- EstatÃ­sticas detalhadas
- Matriz de migraÃ§Ã£o entre estados
- RelatÃ³rio JSON com mÃ©tricas

### 2. Treinamento

#### Treinamento BÃ¡sico
```bash
python train.py
```

#### Personalizar ConfiguraÃ§Ãµes

Edite as configuraÃ§Ãµes no arquivo `train.py`:

```python
MODEL_NAME = "attention_cnn"  # 'cnn', 'resnet', 'attention_cnn', 'lstm'
BATCH_SIZE = 16               # Ajuste conforme sua GPU
NUM_WORKERS = 4               # NÃºmero de CPUs para carregamento de dados
NUM_EPOCHS = 50
LEARNING_RATE = 0.001
```

#### Treinar com GPU
```bash
# AutomÃ¡tico - detecta GPU se disponÃ­vel
python train.py
```

#### Treinar apenas com CPU
```python
# Em train.py, altere:
trainer = AccentDetectorTrainer(
    ...
    device='cpu'
)
```

### 3. Fazer PrediÃ§Ãµes

ApÃ³s treinar, use o modelo para fazer prediÃ§Ãµes:

```bash
python predict.py experiments/attention_cnn_TIMESTAMP/best_model.pth audio.wav
```

Exemplo de saÃ­da:
```
============================================================
Ãudio: audio.wav
Sotaque Predito: SP
ConfianÃ§a: 87.45%

Probabilidades por classe:
     SP: 87.45% â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ
     RJ: 8.32%  â–ˆâ–ˆâ–ˆâ–ˆ
     MG: 2.15%  â–ˆ
     RS: 1.08%  
============================================================
```

### 4. Avaliar Modelo

O script de treinamento jÃ¡ avalia automaticamente o modelo no conjunto de teste ao final do treinamento.

## ğŸ§  Modelos DisponÃ­veis

### 1. **CNN (Convolutional Neural Network)**
- Modelo base com 4 blocos convolucionais
- RÃ¡pido e eficiente
- Bom para datasets menores

### 2. **ResNet (Residual Network)**
- ConexÃµes residuais para treinar redes mais profundas
- Melhor generalizaÃ§Ã£o
- Recomendado para datasets maiores

### 3. **Attention CNN** (Recomendado)
- CNN com mecanismos de atenÃ§Ã£o
- Foca nas partes mais importantes do Ã¡udio
- Melhor performance geral

### 4. **LSTM (Long Short-Term Memory)**
- Modelo recorrente para sequÃªncias temporais
- Captura dependÃªncias de longo prazo
- Mais lento, mas muito eficaz

## âš¡ OtimizaÃ§Ãµes Implementadas

### Multithreading
- **DataLoader Workers**: Carregamento paralelo de dados
- **Persistent Workers**: Workers mantidos vivos entre Ã©pocas
- **Pin Memory**: TransferÃªncia mais rÃ¡pida para GPU

```python
DataLoader(
    dataset,
    num_workers=4,          # 4 threads paralelas
    pin_memory=True,        # OtimizaÃ§Ã£o para GPU
    persistent_workers=True # Workers persistentes
)
```

### Mixed Precision Training
- Usa float16 onde possÃ­vel para economizar memÃ³ria
- MantÃ©m float32 onde necessÃ¡rio para estabilidade
- ~2x mais rÃ¡pido em GPUs modernas

```python
# AutomÃ¡tico com GradScaler
with autocast():
    outputs = model(inputs)
    loss = criterion(outputs, labels)
```

### Data Augmentation
- **Time Stretching**: Varia velocidade do Ã¡udio
- **Pitch Shifting**: Altera tom
- **RuÃ­do Gaussiano**: Aumenta robustez
- Aplicado apenas no conjunto de treino

## ğŸ“Š Resultados

O sistema gera automaticamente:

### Durante o Treinamento
- Loss de treino e validaÃ§Ã£o por Ã©poca
- AcurÃ¡cia de validaÃ§Ã£o
- F1-Score
- Checkpoints do melhor modelo

### ApÃ³s o Treinamento
- **GrÃ¡ficos de treinamento**: `training_history.png`
- **Matriz de confusÃ£o**: `confusion_matrix_teste.png`
- **RelatÃ³rio de classificaÃ§Ã£o**: Precision, Recall, F1 por classe
- **Arquivo JSON**: `training_info.json` com todos os detalhes

### Estrutura de SaÃ­da
```
experiments/
â””â”€â”€ attention_cnn_20231201_120000/
    â”œâ”€â”€ best_model.pth                    # Melhor modelo
    â”œâ”€â”€ training_history.png              # GrÃ¡ficos de treinamento
    â”œâ”€â”€ confusion_matrix_teste.png        # Matriz de confusÃ£o
    â”œâ”€â”€ training_info.json                # InformaÃ§Ãµes do treinamento
    â””â”€â”€ evaluation_teste.json             # MÃ©tricas detalhadas
```

## ğŸ—ï¸ Arquitetura

### Pipeline de Processamento

```
Ãudio WAV
    â†“
Carregamento (librosa)
    â†“
NormalizaÃ§Ã£o
    â†“
Ajuste de Comprimento (5 segundos)
    â†“
Data Augmentation (treino apenas)
    â†“
ExtraÃ§Ã£o de Features
    â”œâ”€â”€ MFCC
    â”œâ”€â”€ Mel-Spectrogram (principal)
    â”œâ”€â”€ Chroma
    â””â”€â”€ Spectral Contrast
    â†“
Modelo Deep Learning
    â†“
ClassificaÃ§Ã£o de Sotaque
```

### Features ExtraÃ­das

1. **Mel-Spectrogram**: RepresentaÃ§Ã£o tempo-frequÃªncia
2. **MFCC**: Coeficientes cepstrais de mel
3. **Delta MFCC**: Primeira e segunda derivadas
4. **Chroma**: CaracterÃ­sticas harmÃ´nicas
5. **Spectral Contrast**: Contraste espectral

## ğŸ“ Boas PrÃ¡ticas Implementadas

- âœ… **Stratified Split**: DivisÃ£o estratificada por classe
- âœ… **Cross-Validation Ready**: FÃ¡cil adaptaÃ§Ã£o para k-fold
- âœ… **Reproducibilidade**: Seeds fixadas
- âœ… **Logging Completo**: Todas as mÃ©tricas salvas
- âœ… **Checkpoint System**: Salva melhor modelo automaticamente
- âœ… **Early Stopping**: Para quando nÃ£o hÃ¡ melhoria
- âœ… **Learning Rate Scheduling**: Ajuste automÃ¡tico
- âœ… **Gradient Scaling**: Para mixed precision
- âœ… **Memory Optimization**: Pin memory e non-blocking transfers

## ğŸ“ˆ Dicas de Performance

### Para Melhorar AcurÃ¡cia
1. Aumente o nÃºmero de Ã©pocas
2. Use o modelo `attention_cnn` ou `resnet`
3. Ajuste o learning rate (tente 0.0001 ou 0.0005)
4. Aumente data augmentation

### Para Treinar Mais RÃ¡pido
1. Use GPU se disponÃ­vel
2. Aumente `batch_size` (se memÃ³ria permitir)
3. Aumente `num_workers` (4-8 geralmente ideal)
4. Use mixed precision training
5. Reduza resoluÃ§Ã£o de features se necessÃ¡rio

### Para Economizar MemÃ³ria
1. Reduza `batch_size`
2. Use modelo `cnn` ao invÃ©s de `resnet`
3. Reduza nÃºmero de mel bands
4. Desative mixed precision se causar problemas

## ğŸ› Troubleshooting

### Erro: "Out of Memory"
- Reduza `batch_size`
- Reduza `num_workers`
- Use CPU ao invÃ©s de GPU

### Erro: "DataLoader Workers"
- No Windows, defina `num_workers=0`
- Ou use: `persistent_workers=False`

### Modelo nÃ£o aprende (loss nÃ£o diminui)
- Reduza learning rate
- Verifique balanceamento de classes
- Aumente nÃºmero de Ã©pocas
- Verifique data augmentation (pode estar muito agressivo)

## ğŸ“ LicenÃ§a

Este projeto Ã© open source e estÃ¡ disponÃ­vel sob a licenÃ§a MIT.

## ğŸ¤ Contribuindo

ContribuiÃ§Ãµes sÃ£o bem-vindas! Sinta-se Ã  vontade para abrir issues ou pull requests.

## ğŸ“§ Contato

Para dÃºvidas ou sugestÃµes, abra uma issue no repositÃ³rio.

---

**Desenvolvido com â¤ï¸ usando PyTorch e as melhores prÃ¡ticas de Deep Learning**


